# references

## Singularity
- xer2.5.2 docs: https://docs.sylabs.io/guides/2.5/user-guide/installation.html#requesting-an-installation
- about singularity: https://rnakato.hatenablog.jp/entry/2019/08/23/144656
- docker image to docker hub: https://chigusa-web.com/blog/dockerfile%E3%82%92%E3%83%93%E3%83%AB%E3%83%89%E3%81%97%E3%81%A6docker-hub%E3%81%AB%E5%85%AC%E9%96%8B%E3%81%99%E3%82%8B/

## SPARQL
- https://qiita.com/uedayou/items/9e4c6029a2cb6b76de9f

## DBpedia
- https://qiita.com/pika_shi/items/eb56fc205e2d670062ae
- https://qiita.com/AAA0125/items/ba73bc216916d158dc90

## GCE docker
- https://qiita.com/karaage0703/items/77d6d75db9105a5e8983
- https://qiita.com/jhorikawa_err/items/fb9c03c0982c29c5b6d5

## Instance level recognition
- [Instance-level Recognition](https://towardsdatascience.com/instance-level-recognition-6afa229e2151)

## resnet
- https://aizine.ai/cnn-0801/
- http://pchun.work/resnet%E3%82%92fine-tuning%E3%81%97%E3%81%A6%E8%87%AA%E5%88%86%E3%81%8C%E7%94%A8%E6%84%8F%E3%81%97%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%95%E3%81%9B%E3%82%8B/#i-2
- https://pystyle.info/pytorch-how-to-use-pretrained-model/

## few-shot
- https://spjai.com/keras-fine-tuning/

## data collection
- https://mtmt-nlp.com/?p=5
- [icrawler](https://icrawler.readthedocs.io/en/latest/)
- [機械学習のデータの集め方](https://qiita.com/nonbiri15/items/f5c5c4357458bfeb03bb)

## pre-processing
- https://www.mgo-tec.com/blog-entry-colab-dataset01.html
- https://axa.biopapyrus.jp/deep-learning/sample/image-shape.html

## method of mizuno-san
- https://docs.google.com/presentation/d/1JCk3mXnx4DpVSHhqqnmepY5Mtwhp1E5U/edit#slide=id.p19
- https://github.com/bird0401/Visual-Entity-Linking-for-Proper-Nouns/blob/main/src/03_create_testdata.py

## dataset
- [VTKEL: A resource for Visual-Textual-Knowledge Entity Linking](https://dl.acm.org/doi/pdf/10.1145/3341105.3373958?casa_token=9E8DWM1X3XQAAAAA:_IAmuLlswCayT6v5ibWmnDmQvSq35yygh4PGXIW0_EMDMTkEolzR3cRJSuTvgwShCdgofGKeBDWV)
- [Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models](https://arxiv.org/pdf/1505.04870.pdf)
- [On Visual-Textual-Knowledge Entity Linking](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9031450)
- [Jointly Linking Visual and Textual Entity Mentions with Background Knowledge](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7298199/pdf/978-3-030-51310-8_Chapter_24.pdf)
- [Google Landmarks Dataset v2 A Large-Scale Benchmark for Instance-Level Recognition and Retrieval](https://arxiv.org/pdf/2004.01804.pdf)
  - [kaggle site](https://www.kaggle.com/competitions/landmark-recognition-2020/data)

## entity linking
[Entity Linking チュートリアル 前編　ざっくりとした歴史編](https://qiita.com/izuna385/items/9d658620b9b96b0b4ec9)

# tech stack
- tmux 
- cron
