{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8a3b19-910b-4a3a-ba7a-863948589b7f",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142ca8cd-db8d-49e5-b5f3-941185dc08cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.7.3)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations) (6.0)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.7.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.22.1-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Installing collected packages: tifffile, opencv-python-headless, imageio, scikit-image, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.0 imageio-2.22.1 opencv-python-headless-4.6.0.66 qudida-0.0.4 scikit-image-0.19.3 tifffile-2021.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3862ce14-bf60-4ea1-a479-3272b076fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e15c5-3752-4957-a01a-41cbe418f70d",
   "metadata": {},
   "source": [
    "# Configuration and Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "afd1ee7b-8158-46ad-87f3-266e647b376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 2022,\n",
    "          \"epochs\": 4,\n",
    "          \"img_size\": 448,\n",
    "          \"model_name\": \"tf_efficientnet_b0_ns\",\n",
    "          \"num_classes\": 15587,\n",
    "          \"embedding_size\": 512,\n",
    "          \"train_batch_size\": 32,\n",
    "          \"valid_batch_size\": 64,\n",
    "          \"learning_rate\": 1e-4,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-6,\n",
    "          \"n_fold\": 5,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          # ArcFace Hyperparameters\n",
    "          \"s\": 30.0, \n",
    "          \"m\": 0.50,\n",
    "          \"ls_eps\": 0.0,\n",
    "          \"easy_margin\": False\n",
    "          }\n",
    "\n",
    "ROOT_DIR = './data/imgs'\n",
    "TRAIN_DIR = './imgs/data/train'\n",
    "TEST_DIR = './imgs/data/test'\n",
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "07ccfba9-5d25-4ae5-b6d9-0f660cd70e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client creating using default project: root-beanbag-354111\n"
     ]
    }
   ],
   "source": [
    "# function to query for BQ\n",
    "\n",
    "location = \"asia-northeast1\"\n",
    "client = bigquery.Client(location=location, project=\"root-beanbag-354111\")\n",
    "print(\"Client creating using default project: {}\".format(client.project))\n",
    "\n",
    "def query2df(query):\n",
    "    query = query\n",
    "    query_job = client.query(\n",
    "        query,\n",
    "        # Location must match that of the dataset(s) referenced in the query.\n",
    "        location=location\n",
    "    )  # API request - starts the query\n",
    "\n",
    "    df = query_job.to_dataframe()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a62da-2a27-4549-8568-eb44ca5ab87b",
   "metadata": {},
   "source": [
    "# import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9ac1dc9f-16ae-425a-a52d-3d56f0f307ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>path</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>./imgs/Q7254/image_0000.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>./imgs/Q7254/image_0001.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>./imgs/Q7254/image_0002.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>./imgs/Q7254/image_0003.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>./imgs/Q7254/image_0004.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_id                         path wikidata_id           name\n",
       "0       1  ./imgs/Q7254/image_0000.jpg       Q7254  Affenpinscher\n",
       "1       2  ./imgs/Q7254/image_0001.jpg       Q7254  Affenpinscher\n",
       "2       3  ./imgs/Q7254/image_0002.jpg       Q7254  Affenpinscher\n",
       "3       4  ./imgs/Q7254/image_0003.jpg       Q7254  Affenpinscher\n",
       "4       5  ./imgs/Q7254/image_0004.jpg       Q7254  Affenpinscher"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take table used in this project\n",
    "\n",
    "query = \"\"\"\n",
    "    WITH \n",
    "        full_table AS (\n",
    "            SELECT ip.img_id, ip.path, iw.wikidata_id, n.name\n",
    "            FROM `root-beanbag-354111.scraping_dog_breeds_by_name.img_path` AS ip\n",
    "            INNER JOIN `root-beanbag-354111.scraping_dog_breeds_by_name.img_wikidata_id` AS iw\n",
    "            USING(img_id)\n",
    "            INNER JOIN `root-beanbag-354111.scraping_dog_breeds_by_name.names` AS n\n",
    "            USING(wikidata_id)),\n",
    "        has_morethan3imgs AS (\n",
    "            SELECT wikidata_id, COUNT(wikidata_id)\n",
    "            FROM full_table\n",
    "            GROUP BY wikidata_id\n",
    "            HAVING COUNT(wikidata_id) >= 3)\n",
    "    SELECT img_id, path, wikidata_id, name\n",
    "    FROM full_table\n",
    "    INNER JOIN has_morethan3imgs USING(wikidata_id)\n",
    "\"\"\"\n",
    "df = query2df(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d60a5175-09b5-4d71-8870-d47b9ae096b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_file_path(path):\n",
    "    p = Path(path)\n",
    "    return str(DATA_DIR / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eebae157-01a4-4f61-b36b-248fe0d8f3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>path</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>is_train_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>./imgs/Q7254/image_0000.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0000.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>./imgs/Q7254/image_0001.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0001.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>./imgs/Q7254/image_0002.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0002.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>./imgs/Q7254/image_0003.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0003.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>./imgs/Q7254/image_0004.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0004.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_id                         path wikidata_id           name  \\\n",
       "0       1  ./imgs/Q7254/image_0000.jpg       Q7254  Affenpinscher   \n",
       "1       2  ./imgs/Q7254/image_0001.jpg       Q7254  Affenpinscher   \n",
       "2       3  ./imgs/Q7254/image_0002.jpg       Q7254  Affenpinscher   \n",
       "3       4  ./imgs/Q7254/image_0003.jpg       Q7254  Affenpinscher   \n",
       "4       5  ./imgs/Q7254/image_0004.jpg       Q7254  Affenpinscher   \n",
       "\n",
       "                        file_path  label  is_train_val  \n",
       "0  data/imgs/Q7254/image_0000.jpg    475           1.0  \n",
       "1  data/imgs/Q7254/image_0001.jpg    475           1.0  \n",
       "2  data/imgs/Q7254/image_0002.jpg    475           0.0  \n",
       "3  data/imgs/Q7254/image_0003.jpg    475           1.0  \n",
       "4  data/imgs/Q7254/image_0004.jpg    475           1.0  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to this project's image path\n",
    "df['file_path'] = df['path'].apply(get_train_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d20c3336-5c2d-46a2-bdb0-96deb8d62227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>path</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>./imgs/Q7254/image_0000.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0000.jpg</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>./imgs/Q7254/image_0001.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0001.jpg</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>./imgs/Q7254/image_0002.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0002.jpg</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>./imgs/Q7254/image_0003.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0003.jpg</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>./imgs/Q7254/image_0004.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0004.jpg</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_id                         path wikidata_id           name  \\\n",
       "0       1  ./imgs/Q7254/image_0000.jpg       Q7254  Affenpinscher   \n",
       "1       2  ./imgs/Q7254/image_0001.jpg       Q7254  Affenpinscher   \n",
       "2       3  ./imgs/Q7254/image_0002.jpg       Q7254  Affenpinscher   \n",
       "3       4  ./imgs/Q7254/image_0003.jpg       Q7254  Affenpinscher   \n",
       "4       5  ./imgs/Q7254/image_0004.jpg       Q7254  Affenpinscher   \n",
       "\n",
       "                        file_path  label  \n",
       "0  data/imgs/Q7254/image_0000.jpg    475  \n",
       "1  data/imgs/Q7254/image_0001.jpg    475  \n",
       "2  data/imgs/Q7254/image_0002.jpg    475  \n",
       "3  data/imgs/Q7254/image_0003.jpg    475  \n",
       "4  data/imgs/Q7254/image_0004.jpg    475  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['label'] = encoder.fit_transform(df['wikidata_id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "684d5493-2662-4a8e-a609-23c9fe0b66a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22984"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"le.pkl\", \"wb\") as fp:\n",
    "    joblib.dump(encoder, fp)\n",
    "len(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3a6ed5f2-0e3f-4fdd-bb0a-7a51fb796cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18387, 4597)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_indices, test_indices = train_test_split(list(range(len(df.label))), test_size=0.2, stratify=df.label)\n",
    "df.loc[train_val_indices, \"is_train_val\"] = 1\n",
    "df.loc[test_indices, \"is_train_val\"] = 0\n",
    "df_train, df_test = df[df[\"is_train_val\"] == 1].reset_index(), df[df[\"is_train_val\"] == 0].reset_index()\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8f416ff2-9797-4ab8-b007-c1225271e112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>img_id</th>\n",
       "      <th>path</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>is_train_val</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>./imgs/Q7254/image_0000.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0000.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>./imgs/Q7254/image_0001.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0001.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>./imgs/Q7254/image_0002.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0002.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>./imgs/Q7254/image_0003.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0003.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>./imgs/Q7254/image_0004.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0004.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>./imgs/Q7254/image_0006.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0006.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>./imgs/Q7254/image_0007.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0007.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>./imgs/Q7254/image_0009.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0009.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>./imgs/Q7254/image_0010.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0010.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>./imgs/Q7254/image_0011.jpg</td>\n",
       "      <td>Q7254</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>data/imgs/Q7254/image_0011.jpg</td>\n",
       "      <td>475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  img_id                         path wikidata_id           name  \\\n",
       "0      0       1  ./imgs/Q7254/image_0000.jpg       Q7254  Affenpinscher   \n",
       "1      1       2  ./imgs/Q7254/image_0001.jpg       Q7254  Affenpinscher   \n",
       "2      2       3  ./imgs/Q7254/image_0002.jpg       Q7254  Affenpinscher   \n",
       "3      3       4  ./imgs/Q7254/image_0003.jpg       Q7254  Affenpinscher   \n",
       "4      4       5  ./imgs/Q7254/image_0004.jpg       Q7254  Affenpinscher   \n",
       "5      6       7  ./imgs/Q7254/image_0006.jpg       Q7254  Affenpinscher   \n",
       "6      7       8  ./imgs/Q7254/image_0007.jpg       Q7254  Affenpinscher   \n",
       "7      9      10  ./imgs/Q7254/image_0009.jpg       Q7254  Affenpinscher   \n",
       "8     10      11  ./imgs/Q7254/image_0010.jpg       Q7254  Affenpinscher   \n",
       "9     11      12  ./imgs/Q7254/image_0011.jpg       Q7254  Affenpinscher   \n",
       "\n",
       "                        file_path  label  is_train_val  kfold  \n",
       "0  data/imgs/Q7254/image_0000.jpg    475           1.0    0.0  \n",
       "1  data/imgs/Q7254/image_0001.jpg    475           1.0    0.0  \n",
       "2  data/imgs/Q7254/image_0002.jpg    475           1.0    0.0  \n",
       "3  data/imgs/Q7254/image_0003.jpg    475           1.0    1.0  \n",
       "4  data/imgs/Q7254/image_0004.jpg    475           1.0    1.0  \n",
       "5  data/imgs/Q7254/image_0006.jpg    475           1.0    2.0  \n",
       "6  data/imgs/Q7254/image_0007.jpg    475           1.0    2.0  \n",
       "7  data/imgs/Q7254/image_0009.jpg    475           1.0    3.0  \n",
       "8  data/imgs/Q7254/image_0010.jpg    475           1.0    3.0  \n",
       "9  data/imgs/Q7254/image_0011.jpg    475           1.0    4.0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df_train, y=df_train.label)):\n",
    "      df_train.loc[val_ , \"kfold\"] = fold\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3985823-7cfd-4532-b9f2-33ccde3f8a95",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d19736d8-bb08-4d85-a38f-bb9d1f2d24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG[\"out_features\"] = len(df_train[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f665d503-d907-4c99-b6ec-5b70dae88a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HappyWhaleDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['file_path'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_names[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': img,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a5987-e84e-4142-a568-98fdf91da8ef",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2b68545e-c87a-4195-9c8a-6a5dce3eeea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HappyWhaleModel(nn.Module):\n",
    "    def __init__(self, model_name, out_features, pretrained=True):\n",
    "        super(HappyWhaleModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(in_features, out_features)\n",
    "        # self.model.classifier = nn.Identity()\n",
    "        # self.model.global_pool = nn.Identity()\n",
    "        # self.pooling = GeM()\n",
    "        # self.embedding = nn.Linear(in_features, embedding_size)\n",
    "        # self.fc = ArcMarginProduct(embedding_size, \n",
    "                                   # CONFIG[\"num_classes\"],\n",
    "                                   # s=CONFIG[\"s\"], \n",
    "                                   # m=CONFIG[\"m\"], \n",
    "                                   # easy_margin=CONFIG[\"ls_eps\"], \n",
    "                                   # ls_eps=CONFIG[\"ls_eps\"])\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        output = self.model(images)\n",
    "        # features = self.model(images)\n",
    "        # pooled_features = self.pooling(features).flatten(1)\n",
    "        # output = self.embedding(pooled_features)\n",
    "        # output = self.fc(embedding, labels)\n",
    "        return output\n",
    "    \n",
    "    # def extract(self, images):\n",
    "    #     features = self.model(images)\n",
    "    #     pooled_features = self.pooling(features).flatten(1)\n",
    "    #     embedding = self.embedding(pooled_features)\n",
    "    #     return embedding\n",
    "\n",
    "    \n",
    "model = HappyWhaleModel(CONFIG['model_name'], CONFIG['out_features'])\n",
    "model.to(CONFIG['device']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1efe74-6a62-49cd-9baa-4deb0d4d8353",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "563ddcd4-9f4f-4978-bb88-d04543e70f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ee76e6e7-fa03-435c-8e45-dd15a6948af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        labels = data['label'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        outputs = model(images, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "            \n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f02c9167-c604-4930-b422-ce7f55707881",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        labels = data['label'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        outputs = model(images, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "437a55a4-6595-44e7-a084-0ed6512060c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    # wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        \n",
    "#         # Log the metrics\n",
    "#         wandb.log({\"Train Loss\": train_epoch_loss})\n",
    "#         wandb.log({\"Valid Loss\": val_epoch_loss})\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            run.summary[\"Best Loss\"] = best_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a56644a9-38d8-49d1-89ae-e41558ca3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2e3c12d4-9e20-48c3-91b9-ed04c3c4daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(df, fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = HappyWhaleDataset(df_train, transforms=data_transforms[\"train\"])\n",
    "    valid_dataset = HappyWhaleDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c06f82d3-c976-4424-9482-c19ad16ecabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/459 [00:00<?, ?it/s]ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "  0% 0/459 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 2796) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 2796) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_141/964280816.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m model, history = run_training(model, optimizer, scheduler,\n\u001b[1;32m     14\u001b[0m                               \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                               num_epochs=CONFIG['epochs'])\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# run.finish()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_141/2657023096.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n\u001b[1;32m     16\u001b[0m                                            \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                            device=CONFIG['device'], epoch=epoch)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
      "\u001b[0;32m/tmp/ipykernel_141/2883186648.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2796) exited unexpectedly"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = prepare_loaders(df_train, fold=0)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n",
    "                       weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "# run = wandb.init(project='HappyWhale', \n",
    "#                  config=CONFIG,\n",
    "#                  job_type='Train',\n",
    "#                  tags=['arcface', 'gem-pooling', 'effnet-b0-ns', '448'],\n",
    "#                  anonymous='must')\n",
    "\n",
    "model, history = run_training(model, optimizer, scheduler,\n",
    "                              device=CONFIG['device'],\n",
    "                              num_epochs=CONFIG['epochs'])\n",
    "\n",
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8c328-205b-4fee-b33c-54e32d1b21f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
